{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras import layers,Model\n",
    "import pickle5 as pickle\n",
    "from   tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from   tensorflow.keras.activations import tanh\n",
    "from   tensorflow.keras.activations import softmax\n",
    "from   numpy import float32\n",
    "from   numpy import byte\n",
    "import json\n",
    "import time\n",
    "import zlib\n",
    "import pickle5 as pickle\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions, get_reshape_size\n",
    "from CaptionModel import CaptionModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class TailModel:\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        self.model = None\n",
    "\n",
    "    def evaluate(self,image):\n",
    "        result = self.model(image)\n",
    "        return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tf.get_logger().setLevel('ERROR')\n",
    "tf.get_logger().setLevel('ERROR')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model = None\n",
    "captionModel = None\n",
    "\n",
    "def handle_load_model(msg,model_path_requested):\n",
    "    global model\n",
    "    global captionModel\n",
    "    if(msg == 'model'):\n",
    "        model_path = cfg.saved_model_path + model_path_requested\n",
    "        Logger.milestone_print(\"Loading model : from %s\" % (model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        print(\"finished loading\")\n",
    "        # model = tf.keras.models.load_model(cfg.temp_path + '/extractor_model', compile=False)\n",
    "        return \"OK\"\n",
    "    if(msg == 'captionModel'):\n",
    "        model_path = cfg.saved_model_path + model_path_requested\n",
    "        captionModel = None\n",
    "        Logger.milestone_print(\"Loading caption model : from %s\" % (model_path))\n",
    "        captionModel = CaptionModel(model_path=model_path)\n",
    "        print(\"finished loading\")\n",
    "        return \"OK\"\n",
    "    if(msg == 'tail_model'):\n",
    "        model_path = cfg.saved_model_path + \"/\" + model_path_requested\n",
    "        Logger.milestone_print(\"Loading model : from %s\" % (model_path))\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        print(\"finished loading\")\n",
    "        return \"OK\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def handle_image_file(msg,shape,reshape_image_size,quantized=False,zlib_compression=False):\n",
    "    \n",
    "    # temp_file = '/tmp/temp.bin'\n",
    "    # f = open(temp_file, \"wb\")\n",
    "    # f.write(msg)\n",
    "    # f.close()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    image = tf.image.decode_jpeg(bytes(msg), channels=3)\n",
    "    image = tf.image.resize(image, (reshape_image_size, reshape_image_size))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 127.5\n",
    "    image -= 1.\n",
    "    image_tensor = tf.expand_dims(image, 0) \n",
    "\n",
    "    # image_tensor = tf.expand_dims(read_image(temp_file, height=reshape_image_size, width=reshape_image_size), 0) \n",
    "    features, result = model(image_tensor)\n",
    "    reshape_size = get_reshape_size(reshape_image_size)\n",
    "    features = tf.reshape(features, [1, reshape_size*reshape_size, 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def preprocess_image(image,reshape_image_size):\n",
    "    image = tf.squeeze(image,[0])\n",
    "    image = tf.image.resize(image, (reshape_image_size, reshape_image_size))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 127.5\n",
    "    image -= 1.\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def handle_rgb_buffer(msg,shape,reshape_image_size,quantized=False,zlib_compression=False):\n",
    "    t0 = time.perf_counter()\n",
    "    if(zlib_compression == True):\n",
    "        msg = zlib.decompress(msg)\n",
    "    generated_np_array = np.frombuffer(msg, dtype=float32)\n",
    "    generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "    generated_image_np_array = generated_np_array.reshape(shape)\n",
    "    image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "    image_tensor = preprocess_image(image_tensor,reshape_image_size)\n",
    "\n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,get_reshape_size(reshape_image_size)*get_reshape_size(reshape_image_size), 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def handle_image_tensor(msg,shape,reshape_image_size,quantized=False,zlib_compression=False):\n",
    "    t0 = time.perf_counter()\n",
    "    if(zlib_compression == True):\n",
    "        msg = zlib.decompress(msg)\n",
    "    if(quantized == True):\n",
    "        generated_np_array = np.frombuffer(msg, dtype=np.uint8)\n",
    "        # generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "        # generated_image_np_array = generated_np_array.reshape(shape)\n",
    "        y = tf.bitcast(generated_np_array, tf.uint8)\n",
    "        image_tensor = tf.cast(y, tf.float32)\n",
    "        image_tensor = tf.reshape(image_tensor,shape )\n",
    "        # image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "    else:\n",
    "        generated_np_array = np.frombuffer(msg, dtype=float32)\n",
    "        generated_np_array = np.frombuffer(generated_np_array, dtype=float32)\n",
    "        generated_image_np_array = generated_np_array.reshape(shape)\n",
    "        image_tensor = tf.convert_to_tensor(generated_image_np_array, dtype=tf.float32)\n",
    "\n",
    "    features, result = model(image_tensor)\n",
    "    features = tf.reshape(features, [1,get_reshape_size(reshape_image_size)*get_reshape_size(reshape_image_size), 2048])\n",
    "    caption_tensor = captionModel.evaluate(features)\n",
    "    t1 = time.perf_counter() - t0\n",
    "\n",
    "    top_predictions, predictions_prob = get_predictions(cfg, result)\n",
    "\n",
    "    send_json_dict = {}\n",
    "    send_json_dict['response'] = 'OK'\n",
    "    send_json_dict['predictions'] = top_predictions\n",
    "    send_json_dict['predictions_prob'] = predictions_prob\n",
    "    send_json_dict['predicted_captions'] = caption_tensor\n",
    "    send_json_dict['tail_model_time'] = t1\n",
    "\n",
    "    app_json = json.dumps(send_json_dict)\n",
    "\n",
    "    return str(app_json)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Logger.set_log_level(1)\n",
    "# logger = Logger()\n",
    "tk = TimeKeeper()\n",
    "cfg = Config(None)\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tailModel = TailModel(cfg)\n",
    "server = Server(cfg)\n",
    "server.register_callback('load_model_request',handle_load_model)\n",
    "server.register_callback('rgb_buffer',handle_rgb_buffer)\n",
    "server.register_callback('intermediate_tensor',handle_image_tensor)\n",
    "server.register_callback('jpeg_buffer',handle_image_file)\n",
    "server.accept_connections()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53d8a323e6010706682c07af791323eacfc072764aa514c33420848fded080be"
  },
  "kernelspec": {
   "display_name": "py373",
   "language": "python",
   "name": "py373"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
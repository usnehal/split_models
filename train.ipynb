{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ],
   "outputs": [],
   "metadata": {
    "id": "1jVKNjhdLFUQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU device not found\n"
     ]
    }
   ],
   "metadata": {
    "id": "CET-72i5EmKn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import  functools\n",
    "import  tensorflow as tf\n",
    "import  tensorflow_datasets as tfds\n",
    "from    tensorflow.keras.utils import to_categorical\n",
    "import  matplotlib.pyplot as plt\n",
    "from    tensorflow.keras import layers\n",
    "from    tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from    tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from common.constants import test, BoxField, DatasetField\n",
    "from common.config import Config\n",
    "from common.logger import Logger\n",
    "from common.communication import Client\n",
    "from common.communication import Server\n",
    "from common.helper import ImagesInfo \n",
    "from common.timekeeper import TimeKeeper\n",
    "from common.helper import read_image, filt_text, get_predictions,process_predictions\n",
    "from CaptionModel import CaptionModel\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "data_dir='/home/suphale/coco'\n",
    "N_LABELS = 80\n",
    "N_EPOCHS = 1\n",
    "TRAIN_MODE = False\n",
    "# split_train = \"train\"\n",
    "# split_val = \"validation\"\n",
    "split_train = \"train[:1%]\"\n",
    "split_val = \"validation[:1%]\"\n",
    "h_image_height = 299\n",
    "h_image_width = 299\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tk = TimeKeeper()\n",
    "cfg = Config()\n",
    "client = Client(cfg)\n",
    "imagesInfo = ImagesInfo(cfg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class BoxField:\n",
    "    BOXES = 'bbox'\n",
    "    KEYPOINTS = 'keypoints'\n",
    "    LABELS = 'label'\n",
    "    MASKS = 'masks'\n",
    "    NUM_BOXES = 'num_boxes'\n",
    "    SCORES = 'scores'\n",
    "    WEIGHTS = 'weights'\n",
    "\n",
    "class DatasetField:\n",
    "    IMAGES = 'images'\n",
    "    IMAGES_INFO = 'images_information'\n",
    "    IMAGES_PMASK = 'images_padding_mask'\n",
    "\n",
    "def my_preprocess(inputs):\n",
    "    image = inputs['image']\n",
    "    image = tf.image.resize(image, (h_image_height, h_image_width))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 127.5\n",
    "    image -= 1.\n",
    "\n",
    "    targets = inputs['objects']\n",
    "\n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
    "\n",
    "    inputs = {DatasetField.IMAGES: image, DatasetField.IMAGES_INFO: image_information}\n",
    "\n",
    "    # ground_truths = {\n",
    "    #     BoxField.BOXES: targets[BoxField.BOXES] * tf.tile(image_information[tf.newaxis], [1, 2]),\n",
    "    #     BoxField.LABELS: tf.cast(targets[BoxField.LABELS], tf.int32),\n",
    "    #     BoxField.NUM_BOXES: tf.shape(targets[BoxField.LABELS]),\n",
    "    #     BoxField.WEIGHTS: tf.fill(tf.shape(targets[BoxField.LABELS]), 1.0)\n",
    "    # }\n",
    "    ground_truths = tf.cast(targets[BoxField.LABELS], tf.int32)\n",
    "    ground_truths = tf.one_hot(ground_truths, depth=N_LABELS, dtype=tf.int32)\n",
    "    ground_truths = tf.reduce_sum(ground_truths, 0)\n",
    "    ground_truths = tf.greater( ground_truths, tf.constant( 0 ) )    \n",
    "    ground_truths = tf.where (ground_truths, 1, 0) \n",
    "    return image, ground_truths\n",
    "\n",
    "def expand_dims_for_single_batch(image, ground_truths):\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    ground_truths = tf.expand_dims(ground_truths, axis=0)\n",
    "    return image, ground_truths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=split_train, data_dir=data_dir, shuffle_files=True, download=False, with_info=True)\n",
    "ds_train = ds_train.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_val = tfds.load(name=\"coco/2017\", split=split_val, data_dir=data_dir, shuffle_files=True, download=False)\n",
    "ds_val = ds_val.map(functools.partial(my_preprocess), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function my_preprocess at 0x7f7b583e6560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function my_preprocess at 0x7f7b583e6560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: AutoGraph could not transform <function my_preprocess at 0x7f7b583e6560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "metadata": {
    "id": "1cC2k8osNGFw",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# ds_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and train the network\n"
   ],
   "metadata": {
    "id": "9tt34CM6P-gr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Find total number of classes in the coco dataset\n",
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "print(num_classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet')\n",
    "\n",
    "x = image_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(80, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=image_model.input, outputs=predictions)\n",
    "\n",
    "for layer in image_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss=ncce, metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for layer in model.layers:\n",
    "    if(layer.trainable == True):\n",
    "        print(layer.trainable)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "callbacks = [\n",
    "    TensorBoard(),\n",
    "    ModelCheckpoint('checkpoints/')\n",
    "]\n",
    "\n",
    "model.fit(ds_train, validation_data=ds_val, epochs=N_EPOCHS, callbacks=callbacks)\n",
    "# Save the weights for the serving\n",
    "model.save_weights(cfg.temp_path + '/coco_classification_weights.h5')\n",
    "model.save(cfg.temp_path + '/model')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1183/1183 [==============================] - 435s 332ms/step - loss: 0.1529 - accuracy: 0.5193 - val_loss: 0.0885 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /home/suphale/WorkSpace/temp/model/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: /home/suphale/WorkSpace/temp/model/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualisation of few images"
   ],
   "metadata": {
    "id": "_ZrcN9snlNxh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for test_index in range(10):\n",
    "    sample_img_batch, sample_cap_batch = next(iter(ds_val))\n",
    "    s = model(sample_img_batch)\n",
    "    # plt.imshow(tf.squeeze(sample_img_batch, [0]))\n",
    "\n",
    "    print(\"Reference  : \", end=' ')\n",
    "    n = sample_cap_batch.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.1:\n",
    "            print(\"%s,\" % (classes[index]), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")\n",
    "    print(\"Prediction : \", end=' ')\n",
    "    n = s.numpy()\n",
    "    index = 0\n",
    "    for x in n[0]:\n",
    "        if x > 0.5:\n",
    "            print(\"%s(%.2f),\" % (classes[index],x), end=' ')\n",
    "        index += 1\n",
    "    print(\"\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reference  :  remote, book, \n",
      "Prediction :  \n",
      "Reference  :  person, tennis racket, \n",
      "Prediction :  person(0.88), tennis racket(0.54), \n",
      "Reference  :  person, bus, book, \n",
      "Prediction :  \n",
      "Reference  :  remote, book, \n",
      "Prediction :  \n",
      "Reference  :  person, tennis racket, \n",
      "Prediction :  person(0.88), tennis racket(0.54), \n",
      "Reference  :  person, bus, book, \n",
      "Prediction :  \n",
      "Reference  :  person, tennis racket, \n",
      "Prediction :  person(0.88), tennis racket(0.54), \n",
      "Reference  :  person, tennis racket, \n",
      "Prediction :  person(0.88), tennis racket(0.54), \n",
      "Reference  :  person, bus, book, \n",
      "Prediction :  \n",
      "Reference  :  person, tennis racket, \n",
      "Prediction :  person(0.88), tennis racket(0.54), \n"
     ]
    }
   ],
   "metadata": {
    "id": "LXhTDloWlNxi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard"
   ],
   "metadata": {
    "id": "CD14aaUMEudZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs"
   ],
   "outputs": [],
   "metadata": {
    "id": "Ec4-mdjcR_wy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ds_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py373",
   "language": "python",
   "name": "py373"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}